<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Observability integrations
        | APM Overview [7.4]
      | Elastic
    </title><link rel="home" href="index.html" title="APM Overview [7.4]" /><link rel="up" href="index.html" title="APM Overview [7.4]" /><link rel="prev" href="opentracing.html" title="OpenTracing bridge" /><link rel="next" href="agent-server-compatibility.html" title="Agent and Server compatibility" /><meta name="DC.type" content="Learn/Docs/APM Server/Reference/7.4" /><meta name="DC.subject" content="APM" /><meta name="DC.identifier" content="7.4" /></head><body><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">APM Overview
      [7.4]
    </a></span> » <span class="breadcrumb-node">Observability integrations</span></div><div class="navheader"><span class="prev"><a href="opentracing.html">
              « 
              OpenTracing bridge</a>
           
        </span><span class="next">
           
          <a href="agent-server-compatibility.html">Agent and Server compatibility
               »
            </a></span></div><div class="chapter"><div class="titlepage"><div><div><h1 class="title"><a id="observability-integrations"></a>Observability integrations<a href="https://github.com/elastic/apm-server/edit/7.4/docs/guide/obs-integrations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h1></div></div></div><p>Elastic APM supports integrations with other observability solutions.</p><h3><a id="apm-logging-integration"></a>Logging integration<a href="https://github.com/elastic/apm-server/edit/7.4/docs/guide/obs-integrations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>Many applications use logging frameworks to help record, format, and append an application’s logs.
Elastic APM now offers a way to make your application logs even more useful,
by integrating with the most popular logging frameworks in their respective languages.
This means you can easily inject trace information into your logs,
allowing you to explore logs in the <a class="ulink" href="https://www.elastic.co/guide/en/kibana/7.4/xpack-logs.html" target="_top">Logs app</a>,
then jump straight into the corresponding APM traces — all while preserving the trace context.</p><p>To get started:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">Enable log correlation</li><li class="listitem">Add APM identifiers to your logs</li><li class="listitem">Ingest your logs into Elasticsearch</li></ol></div><h4><a id="_enable_log_correlation"></a>Enable Log correlation<a href="https://github.com/elastic/apm-server/edit/7.4/docs/guide/obs-integrations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Some Agents require you to first enable log correlation in the Agent.
This is done with a configuration variable, and is different for each Agent.
See the relevant <a class="ulink" href="https://www.elastic.co/guide/en/apm/agent/index.html" target="_top">Agent documentation</a> for further information.</p><h4><a id="_add_apm_identifiers_to_your_logs"></a>Add APM identifiers to your logs<a href="https://github.com/elastic/apm-server/edit/7.4/docs/guide/obs-integrations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Once log correlation is enabled,
you must ensure your logs contain APM identifiers.
In some supported frameworks, this is already done for you.
In other scenarios, like for unstructured logs,
you’ll need to add APM identifiers to your logs in any easy to parse manner.</p><p>The identifiers we’re interested in are: <a class="ulink" href="https://www.elastic.co/guide/en/ecs/1.1/ecs-tracing.html" target="_top"><code class="literal">trace.id</code></a> and
<a class="ulink" href="https://www.elastic.co/guide/en/ecs/1.1/ecs-tracing.html" target="_top"><code class="literal">transaction.id</code></a>. Certain Agents also support the <code class="literal">span.id</code> field.</p><p>This process for adding these fields will differ based the Agent you’re using, the logging framework,
and the type and structure of your logs.</p><p>See the relevant <a class="ulink" href="https://www.elastic.co/guide/en/apm/agent/index.html" target="_top">Agent documentation</a> to learn more.</p><h4><a id="_ingest_your_logs_into_elasticsearch"></a>Ingest your logs into Elasticsearch<a href="https://github.com/elastic/apm-server/edit/7.4/docs/guide/obs-integrations.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Once your logs contain the appropriate identifiers (fields), you need to ingest them into Elasticsearch.
Luckily, we’ve got a tool for that — Filebeat is Elastic’s log shipper.
The <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/filebeat-getting-started.html" target="_top">Filebeat getting started</a>
guide will walk you through the setup process.</p><p>Because logging frameworks and formats vary greatly between different programming languages,
there is no one-size-fits-all approach for ingesting your logs into Elasticsearch.
The following tips should hopefully get you going in the right direction:</p><p><span class="strong strong"><strong>Download Filebeat</strong></span></p><p>There are many ways to download and get started with Filebeat.
Read the <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/filebeat-installation.html" target="_top">Filebeat Installation</a> guide to determine which is best for you.</p><p><span class="strong strong"><strong>Configure Filebeat</strong></span></p><p>Modify the <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/filebeat-configuration.html" target="_top"><code class="literal">filebeat.yml</code></a> configuration file to your needs.
Here are some recommendations:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Set <code class="literal">filebeat.inputs</code> to point to the source of your logs</li><li class="listitem">Point Filebeat to the same Elastic Stack that is receiving your APM data</li><li class="listitem">If you’re using Elastic cloud, set <code class="literal">cloud.id</code> and <code class="literal">cloud.auth</code>.</li><li class="listitem">If your using a manual setup, use <code class="literal">output.elasticsearch.hosts</code>.</li></ul></div><div class="pre_wrapper lang-yml"><pre class="programlisting prettyprint lang-yml">filebeat.inputs:
- type: log <a id="CO1-1"></a><i class="conum" data-value="1"></i>
  paths: <a id="CO1-2"></a><i class="conum" data-value="2"></i>
    - /var/log/*.log
cloud.id: "staging:dXMtZWFzdC0xLmF3cy5mb3VuZC5pbyRjZWMNjN2Q3YTllOTYyNTc0Mw==" <a id="CO1-3"></a><i class="conum" data-value="3"></i>
cloud.auth: "elastic:YOUR_PASSWORD" <a id="CO1-4"></a><i class="conum" data-value="4"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Configures the <code class="literal">log</code> input</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>Path(s) that must be crawled to fetch the log lines</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>Used to resolve the Elasticsearch and Kibana URLs for Elastic Cloud</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-4"><i class="conum" data-value="4"></i></a> </p></td><td valign="top" align="left"><p>Authorization token for Elastic Cloud</p></td></tr></table></div><p><span class="strong strong"><strong>JSON logs</strong></span></p><p>For JSON logs you can use the <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/filebeat-input-log.html" target="_top"><code class="literal">log</code> input</a> to read lines from log files.
Here’s what a sample configuration might look like:</p><div class="pre_wrapper lang-yml"><pre class="programlisting prettyprint lang-yml">filebeat.inputs:
  json.keys_under_root: true <a id="CO2-1"></a><i class="conum" data-value="1"></i>
  json.add_error_key: true <a id="CO2-2"></a><i class="conum" data-value="2"></i>
  json.message_key: message <a id="CO2-3"></a><i class="conum" data-value="3"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO2-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p><code class="literal">true</code> copies JSON keys to the top level in the output document</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO2-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>Tells Filebeat to add an <code class="literal">error.message</code> and <code class="literal">error.type: json</code> key in case of JSON unmarshalling errors</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO2-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>Specifies the JSON key on which to apply line filtering and multiline settings</p></td></tr></table></div><p><span class="strong strong"><strong>Parsing unstructured logs</strong></span></p><p>Consider the following log that is decorated with the <code class="literal">transaction.id</code> and <code class="literal">trace.id</code> fields:</p><div class="pre_wrapper lang-log"><pre class="programlisting prettyprint lang-log">2019-09-18 21:29:49,525 - django.server - ERROR - "GET / HTTP/1.1" 500 27 | elasticapm transaction.id=fcfbbe447b9b6b5a trace.id=f965f4cc5b59bdc62ae349004eece70c span.id=None</pre></div><p>All that’s needed now is an <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/configuring-ingest-node.html" target="_top">ingest node processor</a> to pre-process your logs and
extract these structured fields before they are indexed in Elasticsearch.
To do this, you’d need to create a pipeline that uses Elasticsearch’s <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/grok-processor.html" target="_top">Grok Processor</a>.
Here’s an example:</p><div class="pre_wrapper lang-json"><pre class="programlisting prettyprint lang-json">PUT _ingest/pipeline/log-correlation
{
  "description": "Parses the log correlation IDs out of the raw plain-text log",
  "processors": [
    {
      "grok": {
        "field": "message", <a id="CO3-1"></a><i class="conum" data-value="1"></i>
        "patterns": ["%{GREEDYDATA:message} | elasticapm transaction.id=%{DATA:transaction.id} trace.id=%{DATA:trace.id} span.id=%{DATA:span.id}"] <a id="CO3-2"></a><i class="conum" data-value="2"></i>
      }
    }
  ]
}</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO3-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>The field to use for grok expression parsing</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO3-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>An ordered list of grok expression to match and extract named captures with:
<code class="literal">%{DATA:transaction.id}</code> captures the value of <code class="literal">transaction.id</code>,
<code class="literal">%{DATA:trace.id}</code> captures the value or <code class="literal">trace.id</code>, and
<code class="literal">%{DATA:span.id}</code> captures the value of <code class="literal">span.id</code>.</p></td></tr></table></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>Depending on how you’ve added APM data to your logs,
you may need to tweak this grok pattern in order to work for your setup.
In addition, it’s possible to extract more structure out of your logs.
Make sure to follow the <a class="ulink" href="https://www.elastic.co/guide/en/ecs/1.1/ecs-field-reference.html" target="_top">Elastic Common Schema</a>
when defining which fields you are storing in Elasticsearch.</p></div></div><p>Then, configure Filebeat to use the processor in <code class="literal">filebeat.yml</code>:</p><div class="pre_wrapper lang-json"><pre class="programlisting prettyprint lang-json">output.elasticsearch:
  pipeline: "log-correlation"</pre></div><p>If your logs contain messages that span multiple lines of text (common in Java stack traces),
you’ll also need to configure <a class="ulink" href="https://www.elastic.co/guide/en/beats/filebeat/7.4/multiline-examples.html" target="_top">multiline settings</a>.</p><p>The following example shows how to configure Filebeat to handle a multiline message where the first line of the message begins with a bracket ([).</p><div class="pre_wrapper lang-yml"><pre class="programlisting prettyprint lang-yml">multiline.pattern: '^\['
multiline.negate: true
multiline.match: after</pre></div></div><div class="navfooter"><span class="prev"><a href="opentracing.html">
              « 
              OpenTracing bridge</a>
           
        </span><span class="next">
           
          <a href="agent-server-compatibility.html">Agent and Server compatibility
               »
            </a></span></div></body></html>
