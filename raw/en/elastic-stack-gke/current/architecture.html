<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Architecture
        | Elastic Stack and Google Cloud’s Anthos
      | Elastic
    </title><link rel="home" href="index.html" title="Elastic Stack and Google Cloud’s Anthos" /><link rel="up" href="index.html" title="Elastic Stack and Google Cloud’s Anthos" /><link rel="prev" href="gke-on-prem-introduction.html" title="Introduction" /><link rel="next" href="gke-on-prem-deploy.html" title="Prepare the Kubernetes environment and deploy a sample application" /><meta name="DC.type" content="Learn/Docs/Elastic Stack/Google" /><meta name="DC.subject" content="Elastic Stack" /><meta name="DC.identifier" content="master" /></head><body><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elastic Stack and Google Cloud’s Anthos </a></span> » <span class="breadcrumb-node">Architecture</span></div><div class="navheader"><span class="prev"><a href="gke-on-prem-introduction.html">
              « 
              Introduction</a>
           
        </span><span class="next">
           
          <a href="gke-on-prem-deploy.html">Prepare the Kubernetes environment and deploy a sample application
               »
            </a></span></div><div class="chapter"><div class="titlepage"><div><div><h1 class="title"><a id="architecture"></a>Architecture<a href="https://github.com/elastic/stack-docs/edit/master/docs/en/gke-on-prem/gke-on-prem-architecture.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h1></div></div></div><p>Within each of your GKE On-Prem Kubernetes clusters you will deploy DaemonSets
containing Beats, the lightweight shippers for logs, metrics, network data, etc.
These Beats will autodiscover your applications and GKE On-Prem infrastructure
by synchronizing with the Kubernetes API. Your containers will be managed based
on the process running in them. If you are running NGINX, then Filebeat will
configure itself to collect NGINX logs and Metricbeat will configure itself to
collect NGINX metrics. These pre-packaged collections of configuration details
are called <span class="emphasis"><em>modules</em></span>. You can see the list of available modules in the
documentation for <a class="ulink" href="/guide/en/beats/filebeat/master/filebeat-modules.html" target="_top">Filebeat</a> and
<a class="ulink" href="/guide/en/beats/metricbeat/master/metricbeat-modules.html" target="_top">Metricbeat</a>.</p><p><span class="inlinemediaobject"><img src="images/overview.png" alt="overview" /></span></p><p>A single Elasticsearch cluster with Kibana can be receiving, indexing, storing, and
analyzing logs and metrics from multiple environments. These environments might
be:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">Servers, network devices, virtual machines, etc. in your data centers</li><li class="listitem">One or more GKE On-Prem environments in your data centers</li><li class="listitem">Other data sources</li></ol></div><h3><a id="gke-on-prem-architecture"></a>GKE On-Prem and Elastic Stack Architecture<a href="https://github.com/elastic/stack-docs/edit/master/docs/en/gke-on-prem/gke-on-prem-architecture.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>This example GKE On-Prem Kubernetes cluster has three nodes. Within each node
are application pods and Beats pods. The Beats collect logs and metrics from
their associated Kubernetes node, as well as from the containers deployed on
their associated Kubernetes node.</p><p>Let’s focus on a single three node GKE On-Prem cluster and the connections from
that to the Elasticsearch cluster. Elasticsearch nodes and Kibana are running outside of GKE
On-Prem. Within GKE On-Prem are your applications and Elastic Beats. Beats are
<a class="ulink" href="/products/beats" target="_top">lightweight shippers</a>, and are deployed as Kubernetes
<a class="ulink" href="https://cloud.google.com/kubernetes-engine/docs/concepts/daemonset" target="_top">DaemonSets</a>. By deploying as DaemonSets, Kubernetes guarantees
that there will be one instance of each Beat deployed on each Kubernetes node.
This facilitates efficient processing of the logs and metrics from each node,
and from each pod deployed on that node. As your GKE On-Prem clusters grow in
node count, Beats are deployed along with those nodes.</p><p><span class="inlinemediaobject"><img src="images/nodes.png" alt="nodes" /></span></p><p>Within each GKE On-Prem node there are one or more application pods and the
Beats (plus the standard Kubernetes pods, e.g., kube-dns).</p><h3><a id="gke-on-prem-considerations"></a>Considerations specific to On-Prem deployments of GKE<a href="https://github.com/elastic/stack-docs/edit/master/docs/en/gke-on-prem/gke-on-prem-architecture.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p><span class="inlinemediaobject"><img src="images/loadbalancer.png" alt="loadbalancer" /></span></p><p>Depending on your deployment of GKE On-Prem in your datacenter, you may have to
consider the network topology when exposing services to your network. The sample
application referenced in <a class="link" href="gke-on-prem-deploy.html#gke-on-prem-example" title="Example application">Example Application</a> exposes a
port to the external network. The manifest file specifies an IP address that is
provisioned on the on-premises load balancer. Your configuration will likely be
different, but make sure to take this into consideration when setting up your
environment.</p></div><div class="navfooter"><span class="prev"><a href="gke-on-prem-introduction.html">
              « 
              Introduction</a>
           
        </span><span class="next">
           
          <a href="gke-on-prem-deploy.html">Prepare the Kubernetes environment and deploy a sample application
               »
            </a></span></div></body></html>
