<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Tidying Up Input Text
        | Elasticsearch: The Definitive Guide [1.x]
      | Elastic
    </title><link rel="home" href="index.html" title="Elasticsearch: The Definitive Guide [1.x]" /><link rel="up" href="identifying-words.html" title="Identifying Words" /><link rel="prev" href="icu-tokenizer.html" title="icu_tokenizer" /><link rel="next" href="token-normalization.html" title="Normalizing Tokens" /><meta name="DC.type" content="Learn/Docs/Legacy/Elasticsearch/Definitive Guide/1.x" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="1.x" /><meta name="robots" content="noindex,nofollow" /></head><body><div class="page_header">This information applies to version 1.x of Elasticsearch. For the
most up to date information, see the current version of the
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">
Elasticsearch Reference</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch: The Definitive Guide
      [1.x]
    </a></span> » <span class="breadcrumb-link"><a href="languages.html">Dealing with Human Language</a></span> » <span class="breadcrumb-link"><a href="identifying-words.html">Identifying Words</a></span> » <span class="breadcrumb-node">Tidying Up Input Text</span></div><div class="navheader"><span class="prev"><a href="icu-tokenizer.html">
              « 
              icu_tokenizer</a>
           
        </span><span class="next">
           
          <a href="token-normalization.html">Normalizing Tokens
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="char-filters"></a>Tidying Up Input Text<a href="https://github.com/elastic/elasticsearch-definitive-guide/edit/1.x/210_Identifying_words/50_Tidying_text.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>Tokenizers produce the best results when the input text is clean, valid
text, where <span class="emphasis"><em>valid</em></span> means that it follows the punctuation rules that the
Unicode algorithm expects.<a id="id-1.6.4.11.2.2" class="indexterm"></a>
<a id="id-1.6.4.11.2.3" class="indexterm"></a><a id="id-1.6.4.11.2.4" class="indexterm"></a>
<a id="id-1.6.4.11.2.5" class="indexterm"></a>
<a id="id-1.6.4.11.2.6" class="indexterm"></a>  Quite often, though, the text we need to process
is anything but clean. Cleaning it up before tokenization improves the quality
of the output.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_tokenizing_html"></a>Tokenizing HTML<a href="https://github.com/elastic/elasticsearch-definitive-guide/edit/1.x/210_Identifying_words/50_Tidying_text.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>Passing HTML through the <code class="literal">standard</code> tokenizer or the <code class="literal">icu_tokenizer</code> produces
poor results.<a id="id-1.6.4.11.3.2.3" class="indexterm"></a>  These tokenizers just don’t know what to do with the HTML tags.
For example:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">GET /_analyzer?tokenizer=standard
&lt;p&gt;Some d&amp;eacute;j&amp;agrave; vu &lt;a href="http://somedomain.com&gt;"&gt;website&lt;/a&gt;</pre></div><p>The <code class="literal">standard</code> tokenizer<a id="id-1.6.4.11.3.4.2" class="indexterm"></a>
<a id="id-1.6.4.11.3.4.3" class="indexterm"></a> confuses HTML tags and entities, and emits the
following tokens: <code class="literal">p</code>, <code class="literal">Some</code>, <code class="literal">d</code>, <code class="literal">eacute</code>, <code class="literal">j</code>, <code class="literal">agrave</code>, <code class="literal">vu</code>, <code class="literal">a</code>,
<code class="literal">href</code>, <code class="literal">http</code>, <code class="literal">somedomain.com</code>, <code class="literal">website</code>, <code class="literal">a</code>.  Clearly not what was
intended!</p><p><span class="emphasis"><em>Character filters</em></span> can be added to an analyzer to <a id="id-1.6.4.11.3.5.2" class="indexterm"></a>preprocess the text
<span class="emphasis"><em>before</em></span> it is passed to the tokenizer.  In this case, we can use the
<code class="literal">html_strip</code> character filter<a id="id-1.6.4.11.3.5.5" class="indexterm"></a>
<a id="id-1.6.4.11.3.5.6" class="indexterm"></a><a id="id-1.6.4.11.3.5.7" class="indexterm"></a> to remove HTML tags and to decode HTML entities
such as <code class="literal">&amp;eacute;</code> into the corresponding Unicode characters.</p><p>Character filters can be tested out via the <code class="literal">analyze</code> API by specifying them
in the query string:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">GET /_analyzer?tokenizer=standard&amp;char_filters=html_strip
&lt;p&gt;Some d&amp;eacute;j&amp;agrave; vu &lt;a href="http://somedomain.com&gt;"&gt;website&lt;/a&gt;</pre></div><p>To use them as part of the analyzer, they should be added to a <code class="literal">custom</code>
analyzer definition:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">PUT /my_index
{
    "settings": {
        "analysis": {
            "analyzer": {
                "my_html_analyzer": {
                    "tokenizer":     "standard",
                    "char_filter": [ "html_strip" ]
                }
            }
        }
    }
}</pre></div><p>Once created, our new <code class="literal">my_html_analyzer</code> can be tested with the <code class="literal">analyze</code> API:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">GET /my_index/_analyzer?analyzer=my_html_analyzer
&lt;p&gt;Some d&amp;eacute;j&amp;agrave; vu &lt;a href="http://somedomain.com&gt;"&gt;website&lt;/a&gt;</pre></div><p>This emits the tokens that we expect: <code class="literal">Some</code>, <code class="literal">déjà</code>, <code class="literal">vu</code>, <code class="literal">website</code>.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="_tidying_up_punctuation"></a>Tidying Up Punctuation<a href="https://github.com/elastic/elasticsearch-definitive-guide/edit/1.x/210_Identifying_words/50_Tidying_text.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>The <code class="literal">standard</code> tokenizer and <code class="literal">icu_tokenizer</code> both understand that an
apostrophe <span class="emphasis"><em>within</em></span> a word should be treated as part of the word, while single
quotes that <span class="emphasis"><em>surround</em></span> a word should not.<a id="id-1.6.4.11.4.2.5" class="indexterm"></a>
<a id="id-1.6.4.11.4.2.6" class="indexterm"></a><a id="id-1.6.4.11.4.2.7" class="indexterm"></a>
<a id="id-1.6.4.11.4.2.8" class="indexterm"></a><a id="id-1.6.4.11.4.2.9" class="indexterm"></a>
<a id="id-1.6.4.11.4.2.10" class="indexterm"></a> Tokenizing the text <code class="literal">You're my 'favorite'</code>. would correctly emit the tokens <code class="literal">You're, my, favorite</code>.</p><p>Unfortunately,<a id="id-1.6.4.11.4.3.1" class="indexterm"></a> Unicode lists a few characters that are sometimes used
as apostrophes:</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">
<code class="literal">U+0027</code>
</span></dt><dd>
      Apostrophe (<code class="literal">'</code>)—the original ASCII character
</dd><dt><span class="term">
<code class="literal">U+2018</code>
</span></dt><dd>
      Left single-quotation mark (<code class="literal">‘</code>)—opening quote when single-quoting
</dd><dt><span class="term">
<code class="literal">U+2019</code>
</span></dt><dd>
      Right single-quotation mark (<code class="literal">’</code>)—closing quote when single-quoting, but also the  preferred character to use as an apostrophe
</dd></dl></div><p>Both tokenizers treat these three characters as an apostrophe (and thus as
part of the word) when they appear within a word. Then there are another three
apostrophe-like characters:</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">
<code class="literal">U+201B</code>
</span></dt><dd>
      Single high-reversed-9 quotation mark (<code class="literal">‛</code>)—same as <code class="literal">U+2018</code> but differs in appearance
</dd><dt><span class="term">
<code class="literal">U+0091</code>
</span></dt><dd>
      Left single-quotation mark in ISO-8859-1—should not be used in Unicode
</dd><dt><span class="term">
<code class="literal">U+0092</code>
</span></dt><dd>
      Right single-quotation mark in ISO-8859-1—should not be used in Unicode
</dd></dl></div><p>Both tokenizers treat these three characters as word boundaries—a place to
break text into tokens.<a id="id-1.6.4.11.4.7.1" class="indexterm"></a> Unfortunately, some publishers use <code class="literal">U+201B</code> as a
stylized way to write names like <code class="literal">M‛coy</code>, and the second two characters may well
be produced by your word processor, depending on its age.</p><p>Even when using the “acceptable” quotation marks, a word written with a
single right quotation mark—<code class="literal">You’re</code>—is not the same as the word written
with an apostrophe—<code class="literal">You're</code>—which means that a query for one variant
will not find the other.</p><p>Fortunately, it is possible to sort out this mess with the <code class="literal">mapping</code> character
filter,<a id="id-1.6.4.11.4.9.2" class="indexterm"></a>
<a id="id-1.6.4.11.4.9.3" class="indexterm"></a><a id="id-1.6.4.11.4.9.4" class="indexterm"></a> which allows us to replace all instances of one character with
another.  In this case, we will replace all apostrophe variants with the
simple <code class="literal">U+0027</code> apostrophe:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">PUT /my_index
{
  "settings": {
    "analysis": {
      "char_filter": { <a id="CO137-1"></a><i class="conum" data-value="1"></i>
        "quotes": {
          "type": "mapping",
          "mappings": [ <a id="CO137-2"></a><i class="conum" data-value="2"></i>
            "\\u0091=&gt;\\u0027",
            "\\u0092=&gt;\\u0027",
            "\\u2018=&gt;\\u0027",
            "\\u2019=&gt;\\u0027",
            "\\u201B=&gt;\\u0027"
          ]
        }
      },
      "analyzer": {
        "quotes_analyzer": {
          "tokenizer":     "standard",
          "char_filter": [ "quotes" ] <a id="CO137-3"></a><i class="conum" data-value="3"></i>
        }
      }
    }
  }
}</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO137-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
We define a custom <code class="literal">char_filter</code> called <code class="literal">quotes</code> that
    maps all apostrophe variants to a simple apostrophe.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO137-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>
For clarity, we have used the JSON Unicode escape syntax
    for each character, but we could just have used the
    characters themselves: <code class="literal">"‘=&gt;'"</code>.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO137-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>
We use our custom <code class="literal">quotes</code> character filter to create
    a new analyzer called <code class="literal">quotes_analyzer</code>.
</p></td></tr></table></div><p>As always, we test the analyzer after creating it:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">GET /my_index/_analyze?analyzer=quotes_analyzer
You’re my ‘favorite’ M‛Coy</pre></div><p>This example returns the following tokens, with all of the in-word
quotation marks replaced by apostrophes: <code class="literal">You're</code>, <code class="literal">my</code>, <code class="literal">favorite</code>, <code class="literal">M'Coy</code>.</p><p>The more effort that you put into ensuring that the tokenizer receives good-quality input, the better your search results will be.</p></div></div><div class="navfooter"><span class="prev"><a href="icu-tokenizer.html">
              « 
              icu_tokenizer</a>
           
        </span><span class="next">
           
          <a href="token-normalization.html">Normalizing Tokens
               »
            </a></span></div></body></html>
