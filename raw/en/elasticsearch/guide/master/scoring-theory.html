<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title xmlns="">Theory Behind Relevance Scoring
        | Elasticsearch: The Definitive Guide [master]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch: The Definitive Guide [master]" /><link rel="up" href="controlling-relevance.html" title="Controlling Relevance" /><link rel="prev" href="controlling-relevance.html" title="Controlling Relevance" /><link rel="next" href="practical-scoring-function.html" title="Lucene’s Practical Scoring Function" /><meta xmlns="" name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta xmlns="" name="DC.type" content="Learn/Docs/Legacy/Elasticsearch/Definitive Guide/master" /><meta xmlns="" name="DC.subject" content="Elasticsearch" /><meta xmlns="" name="DC.identifier" content="master" /><meta xmlns="" name="robots" content="noindex,nofollow" /></head><body><div xmlns="" class="page_header">This information may not apply to the latest version of Elasticsearch.
For the most up to date information, see the current version of the
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">
Elasticsearch Reference</a>.
</div><div xmlns="" class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch: The Definitive Guide
      [master]
    </a></span> » <span class="breadcrumb-link"><a href="search-in-depth.html">Search in Depth</a></span> » <span class="breadcrumb-link"><a href="controlling-relevance.html">Controlling Relevance</a></span> » <span class="breadcrumb-node">Theory Behind Relevance Scoring</span></div><div xmlns="" class="navheader"><span class="prev"><a href="controlling-relevance.html">
              « 
              Controlling Relevance</a>
           
        </span><span class="next">
           
          <a href="practical-scoring-function.html">Lucene’s Practical Scoring Function
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="scoring-theory"></a>Theory Behind Relevance Scoring<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>Lucene (and thus Elasticsearch) uses the
<a class="ulink" href="http://en.wikipedia.org/wiki/Standard_Boolean_model" target="_top"><span class="emphasis"><em>Boolean model</em></span></a>
to find matching documents,<a id="id-1.5.8.8.2.2" class="indexterm"></a>
<a id="id-1.5.8.8.2.3" class="indexterm"></a><a id="id-1.5.8.8.2.4" class="indexterm"></a> and a formula called the
<a class="link" href="practical-scoring-function.html" title="Lucene’s Practical Scoring Function"><span class="emphasis"><em>practical scoring function</em></span></a>
to calculate relevance.  This formula borrows concepts from
<a class="ulink" href="http://en.wikipedia.org/wiki/Tfidf" target="_top"><span class="emphasis"><em>term frequency/inverse document frequency</em></span></a> and the
<a class="ulink" href="http://en.wikipedia.org/wiki/Vector_space_model" target="_top"><span class="emphasis"><em>vector space model</em></span></a>
but adds more-modern features like a coordination factor, field length
normalization, and term or query clause boosting.</p><div xmlns="" class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">Don’t be alarmed!  These concepts are not as complicated as the names make
them appear. While this section mentions algorithms, formulae, and mathematical
models, it is intended for consumption by mere humans.  Understanding the
algorithms themselves is not as important as understanding the factors that
influence the outcome.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="boolean-model"></a>Boolean Model<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>The <span class="emphasis"><em>Boolean model</em></span> simply applies the <code class="literal">AND</code>, <code class="literal">OR</code>, and <code class="literal">NOT</code> conditions
expressed in the query to find all the documents that match.<a id="id-1.5.8.8.4.2.5" class="indexterm"></a><a id="id-1.5.8.8.4.2.6" class="indexterm"></a><a id="id-1.5.8.8.4.2.7" class="indexterm"></a> A query for</p><pre class="literallayout">full AND text AND search AND (elasticsearch OR lucene)</pre><p>will include only documents that contain all of the terms <code class="literal">full</code>, <code class="literal">text</code>, and
<code class="literal">search</code>, and either <code class="literal">elasticsearch</code> or <code class="literal">lucene</code>.</p><p>This process is simple and fast.  It is used to exclude any documents that
cannot possibly match the query.</p></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="tfidf"></a>Term Frequency/Inverse Document Frequency (TF/IDF)<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>Once we have a list of matching documents, they need to be ranked by
relevance.<a id="id-1.5.8.8.5.2.1" class="indexterm"></a> Not all documents will contain all the terms, and some terms are
more important than others. The relevance score of the whole document
depends (in part) on the <span class="emphasis"><em>weight</em></span> of each query term that appears in
that document.</p><p>The weight of a term is determined by three factors, which we already
introduced in <a class="xref" href="relevance-intro.html" title="What Is Relevance?">What Is Relevance?</a>. The formulae are included for interest’s
sake, but you are not required to remember them.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="tf"></a>Term frequency<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>How often does the term appear in this document?<a id="id-1.5.8.8.5.4.2.1" class="indexterm"></a>
<a id="id-1.5.8.8.5.4.2.2" class="indexterm"></a> The more often, the
<span class="emphasis"><em>higher</em></span> the weight.  A field containing five mentions of the same term is
more likely to be relevant than a field containing just one mention.
The term frequency is calculated as follows:</p><pre class="literallayout">tf(t in d) = √frequency <a id="CO101-1"></a><i xmlns="" class="conum" data-value="1"></i></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO101-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
The term frequency (<code class="literal">tf</code>) for term <code class="literal">t</code> in document <code class="literal">d</code> is the square root
    of the number of times the term appears in the document.
</p></td></tr></table></div><p>If you don’t care about how often a term appears in a field, and all you care
about is that the term is present, then you can disable term frequencies in
the field mapping:</p><div xmlns="" class="pre_wrapper lang-json"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-json">PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type":          "string",
          "index_options": "docs" <a id="CO102-1"></a><i xmlns="" class="conum" data-value="1"></i>
        }
      }
    }
  }
}</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO102-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
Setting <code class="literal">index_options</code> to <code class="literal">docs</code> will disable term frequencies and term
    positions. A field with this mapping will not count how many times a term
    appears, and will not be usable for phrase or proximity queries.
    Exact-value <code class="literal">not_analyzed</code> string fields use this setting by default.
</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="idf"></a>Inverse document frequency<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>How often does the term appear in all documents in the collection?  The more
often, the <span class="emphasis"><em>lower</em></span> the weight.<a id="id-1.5.8.8.5.5.2.2" class="indexterm"></a><a id="id-1.5.8.8.5.5.2.3" class="indexterm"></a>
<a id="id-1.5.8.8.5.5.2.4" class="indexterm"></a> Common terms like <code class="literal">and</code> or <code class="literal">the</code> contribute
little to relevance, as they appear in most documents, while uncommon terms
like <code class="literal">elastic</code> or <code class="literal">hippopotamus</code> help us zoom in on the most interesting
documents. The inverse document frequency is calculated as follows:</p><pre class="literallayout">idf(t) = 1 + log ( numDocs / (docFreq + 1)) <a id="CO103-1"></a><i xmlns="" class="conum" data-value="1"></i></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO103-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
The inverse document frequency (<code class="literal">idf</code>) of term <code class="literal">t</code> is the
    logarithm of the number of documents in the index, divided by
    the number of documents that contain the term.
</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="field-norm"></a>Field-length norm<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>How long is the field?  <a id="id-1.5.8.8.5.6.2.1" class="indexterm"></a>
<a id="id-1.5.8.8.5.6.2.2" class="indexterm"></a><a id="id-1.5.8.8.5.6.2.3" class="indexterm"></a>The shorter the field, the <span class="emphasis"><em>higher</em></span> the weight. If a
term appears in a short field, such as a <code class="literal">title</code> field, it is more likely that
the content of that field is <span class="emphasis"><em>about</em></span> the term than if the same term appears
in a much bigger <code class="literal">body</code> field. The field length norm is calculated as follows:</p><pre class="literallayout">norm(d) = 1 / √numTerms <a id="CO104-1"></a><i xmlns="" class="conum" data-value="1"></i></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO104-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
The field-length norm (<code class="literal">norm</code>) is the inverse square root of the number of terms
    in the field.
</p></td></tr></table></div><p>While the field-length <a id="id-1.5.8.8.5.6.5.1" class="indexterm"></a>
<a id="id-1.5.8.8.5.6.5.2" class="indexterm"></a>norm is important for full-text search, many other
fields don’t need norms. Norms consume approximately 1 byte per <code class="literal">string</code> field
per document in the index, whether or not a document contains the field.  Exact-value <code class="literal">not_analyzed</code> string fields have norms disabled by default,
but you can use the field mapping to disable norms on <code class="literal">analyzed</code> fields as
well:</p><div xmlns="" class="pre_wrapper lang-json"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-json">PUT /my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "text": {
          "type": "string",
          "norms": { "enabled": false } <a id="CO105-1"></a><i xmlns="" class="conum" data-value="1"></i>
        }
      }
    }
  }
}</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO105-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
This field will not take the field-length norm into account.  A long field
    and a short field will be scored as if they were the same length.
</p></td></tr></table></div><p>For use cases such as logging, norms are not useful.  All you care about is
whether a field contains a particular error code or a particular browser
identifier. The length of the field does not affect the outcome.  Disabling
norms can save a significant amount of memory.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="_putting_it_together"></a>Putting it together<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4></div></div></div><p>These three factors—term frequency, inverse document frequency, and field-length norm—are calculated and stored at index time.<a id="id-1.5.8.8.5.7.2.1" class="indexterm"></a>
<a id="id-1.5.8.8.5.7.2.2" class="indexterm"></a>  Together, they are
used to calculate the <span class="emphasis"><em>weight</em></span> of a single term in a particular document.</p><div xmlns="" class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">When we refer to <span class="emphasis"><em>documents</em></span> in the preceding formulae, we are actually talking about
a field within a document.  Each field has its own inverted index and thus,
for TF/IDF purposes, the value of the field is the value of the document.</p></div></div><p>When we run a simple <code class="literal">term</code> query with <code class="literal">explain</code> set to <code class="literal">true</code> (see
<a class="xref" href="relevance-intro.html#explain" title="Understanding the Score">Understanding the Score</a>), you will see that the only factors involved in calculating the
score are the ones explained in the preceding sections:</p><div xmlns="" class="pre_wrapper pagebreak-before lang-json"><pre xmlns="http://www.w3.org/1999/xhtml" class="pagebreak-before programlisting prettyprint lang-json">PUT /my_index/doc/1
{ "text" : "quick brown fox" }

GET /my_index/doc/_search?explain
{
  "query": {
    "term": {
      "text": "fox"
    }
  }
}</pre></div><p>The (abbreviated) <code class="literal">explanation</code> from the preceding request is as follows:</p><pre class="literallayout">weight(text:fox in 0) [PerFieldSimilarity]:  0.15342641 <a id="CO106-1"></a><i xmlns="" class="conum" data-value="1"></i>
result of:
    fieldWeight in 0                         0.15342641
    product of:
        tf(freq=1.0), with freq of 1:        1.0 <a id="CO106-2"></a><i xmlns="" class="conum" data-value="2"></i>
        idf(docFreq=1, maxDocs=1):           0.30685282 <a id="CO106-3"></a><i xmlns="" class="conum" data-value="3"></i>
        fieldNorm(doc=0):                    0.5 <a id="CO106-4"></a><i xmlns="" class="conum" data-value="4"></i></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO106-1"><i xmlns="" class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>
The final <code class="literal">score</code> for term <code class="literal">fox</code> in field <code class="literal">text</code> in the document with internal
    Lucene doc ID <code class="literal">0</code>.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO106-2"><i xmlns="" class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>
The term <code class="literal">fox</code> appears once in the <code class="literal">text</code> field in this document.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO106-3"><i xmlns="" class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>
The inverse document frequency of <code class="literal">fox</code> in the <code class="literal">text</code> field in all
    documents in this index.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO106-4"><i xmlns="" class="conum" data-value="4"></i></a> </p></td><td valign="top" align="left"><p>
The field-length normalization factor for this field.
</p></td></tr></table></div><p>Of course, queries usually consist of more than one term, so we need a
way of combining the weights of multiple terms.  For this, we turn to the
vector space model.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="vector-space-model"></a>Vector Space Model<a xmlns="" href="https://github.com/elastic/elasticsearch-definitive-guide/edit/master/170_Relevance/10_Scoring_theory.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>The <span class="emphasis"><em>vector space model</em></span> provides a way of <a id="id-1.5.8.8.6.2.2" class="indexterm"></a>comparing a multiterm query
against a document. The output is a single score that represents how well the
document matches the query.  In order to do this, the model represents both the document
and the query as <span class="emphasis"><em>vectors</em></span>.</p><p>A vector is really just a one-dimensional array containing numbers, for example:</p><pre class="literallayout">[1,2,5,22,3,8]</pre><p>In the vector space<a id="id-1.5.8.8.6.5.1" class="indexterm"></a>
<a id="id-1.5.8.8.6.5.2" class="indexterm"></a> model, each number in the vector is<a id="id-1.5.8.8.6.5.3" class="indexterm"></a>
<a id="id-1.5.8.8.6.5.4" class="indexterm"></a>
<a id="id-1.5.8.8.6.5.5" class="indexterm"></a> the <span class="emphasis"><em>weight</em></span> of a term,
as calculated with <a class="link" href="scoring-theory.html#tfidf" title="Term Frequency/Inverse Document Frequency (TF/IDF)">term frequency/inverse document frequency</a>.</p><div xmlns="" class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">While TF/IDF is the default way of calculating term weights for the vector
space model, it is not the only way.  Other models like Okapi-BM25 exist and
are available in Elasticsearch.  TF/IDF is the default because it is a
simple, efficient algorithm that produces high-quality search results and
has stood the test of time.</p></div></div><p>Imagine that we have a query for “happy hippopotamus.”  A common word like
<code class="literal">happy</code> will have a low weight, while an uncommon term like <code class="literal">hippopotamus</code>
will have a high weight. Let’s assume that <code class="literal">happy</code> has a weight of 2 and
<code class="literal">hippopotamus</code> has a weight of 5.  We can plot this simple two-dimensional
vector—<code class="literal">[2,5]</code>—as a line on a graph starting at point (0,0) and
ending at point (2,5), as shown in <a class="xref" href="scoring-theory.html#img-vector-query" title="Figure 27. A two-dimensional query vector for “happy hippopotamus” represented">Figure 27, “A two-dimensional query vector for “happy hippopotamus” represented”</a>.</p><div class="figure"><a id="img-vector-query"></a><p class="title"><strong>Figure 27. A two-dimensional query vector for “happy hippopotamus” represented</strong></p><div class="figure-contents"><div class="mediaobject"><img src="images/elas_17in01.png" alt="The query vector plotted on a graph" /></div></div></div><p>Now, imagine we have three documents:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
I am <span class="emphasis"><em>happy</em></span> in summer.
</li><li class="listitem">
After Christmas I’m a <span class="emphasis"><em>hippopotamus</em></span>.
</li><li class="listitem">
The <span class="emphasis"><em>happy hippopotamus</em></span> helped Harry.
</li></ol></div><p>We can create a similar vector for each document, consisting of the weight of
each query term—<code class="literal">happy</code> and <code class="literal">hippopotamus</code>—that appears in the
document, and plot these vectors on the same graph, as shown in <a class="xref" href="scoring-theory.html#img-vector-docs" title="Figure 28. Query and document vectors for “happy hippopotamus”">Figure 28, “Query and document vectors for “happy hippopotamus””</a>:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Document 1: <code class="literal">(happy,____________)</code>—<code class="literal">[2,0]</code>
</li><li class="listitem">
Document 2: <code class="literal">( ___ ,hippopotamus)</code>—<code class="literal">[0,5]</code>
</li><li class="listitem">
Document 3: <code class="literal">(happy,hippopotamus)</code>—<code class="literal">[2,5]</code>
</li></ul></div><div class="figure"><a id="img-vector-docs"></a><p class="title"><strong>Figure 28. Query and document vectors for “happy hippopotamus”</strong></p><div class="figure-contents"><div class="mediaobject"><img src="images/elas_17in02.png" alt="The query and document vectors plotted on a graph" /></div></div></div><p>The nice thing about vectors is that they can be compared. By measuring the
angle between the query vector and the document vector, it is possible to
assign a relevance score to each document. The angle between document 1 and
the query is large, so it is of low relevance.  Document 2 is closer to the
query, meaning that it is reasonably relevant, and document 3 is a perfect
match.</p><div xmlns="" class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">In practice, only two-dimensional vectors (queries with two terms) can  be
plotted easily on a graph. Fortunately, <span class="emphasis"><em>linear algebra</em></span>—the branch of
mathematics that deals with vectors—provides tools to compare the
angle between multidimensional vectors, which means that we can apply the
same principles explained above to queries that consist of many terms.</p><p xmlns="http://www.w3.org/1999/xhtml">You can read more about how to compare two vectors by using <a class="ulink" href="http://en.wikipedia.org/wiki/Cosine_similarity" target="_top"><span class="emphasis"><em>cosine similarity</em></span></a>.</p></div></div><p>Now that we have talked about the theoretical basis of scoring, we can move on
to see how scoring is implemented in Lucene.<a id="id-1.5.8.8.6.16.1" class="indexterm"></a>
<a id="id-1.5.8.8.6.16.2" class="indexterm"></a></p></div></div><div xmlns="" class="navfooter"><span class="prev"><a href="controlling-relevance.html">
              « 
              Controlling Relevance</a>
           
        </span><span class="next">
           
          <a href="practical-scoring-function.html">Lucene’s Practical Scoring Function
               »
            </a></span></div></body></html>