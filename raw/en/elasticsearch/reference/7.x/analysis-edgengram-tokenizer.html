<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Edge NGram Tokenizer
        | Elasticsearch Reference [7.x]
      | Elastic
    </title><link rel="home" href="index.html" title="Elasticsearch Reference [7.x]" /><link rel="up" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="prev" href="analysis-classic-tokenizer.html" title="Classic Tokenizer" /><link rel="next" href="max-gram-limits.html" title="Limitations of the max_gram parameter" /><meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/7.x" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="7.x" /></head><body><div class="page_header">You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference
      [7.x]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span> » <span class="breadcrumb-node">Edge NGram Tokenizer</span></div><div class="navheader"><span class="prev"><a href="analysis-classic-tokenizer.html">
              « 
              Classic Tokenizer</a>
           
        </span><span class="next">
           
          <a href="max-gram-limits.html">Limitations of the <code class="literal">max_gram</code> parameter
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-edgengram-tokenizer"></a>Edge NGram Tokenizer<a href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>The <code class="literal">edge_ngram</code> tokenizer first breaks text down into words whenever it
encounters one of a list of specified characters, then it emits
<a class="ulink" href="https://en.wikipedia.org/wiki/N-gram" target="_top">N-grams</a> of each word where the start of
the N-gram is anchored to the beginning of the word.</p><p>Edge N-Grams are useful for <span class="emphasis"><em>search-as-you-type</em></span> queries.</p><div class="tip admon"><div class="icon"></div><div class="admon_content"><p>When you need <span class="emphasis"><em>search-as-you-type</em></span> for text which has a widely known
order, such as movie or song titles, the
<a class="link" href="search-suggesters.html#completion-suggester" title="Completion Suggester">completion suggester</a> is a much more efficient
choice than edge N-grams.  Edge N-grams have the advantage when trying to
autocomplete words that can appear in any order.</p></div></div><h3><a id="_example_output_10"></a>Example output<a href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>With the default settings, the <code class="literal">edge_ngram</code> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <code class="literal">1</code> and maximum length
<code class="literal">2</code>:</p><div class="pre_wrapper lang-console"><pre class="programlisting prettyprint lang-console">POST _analyze
{
  "tokenizer": "edge_ngram",
  "text": "Quick Fox"
}</pre></div><div class="console_widget" data-snippet="snippets/777.console"></div><p>The above sentence would produce the following terms:</p><div class="pre_wrapper lang-text"><pre class="programlisting prettyprint lang-text">[ Q, Qu ]</pre></div><div class="note admon"><div class="icon"></div><div class="admon_content"><p>These default gram lengths are almost entirely useless.  You need to
configure the <code class="literal">edge_ngram</code> before using it.</p></div></div><h3><a id="_configuration_11"></a>Configuration<a href="https://github.com/elastic/elasticsearch/edit/7.x/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>The <code class="literal">edge_ngram</code> tokenizer accepts the following parameters:</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">min_gram</code></span></dt><dd>Minimum length of characters in a gram.  Defaults to <code class="literal">1</code>.</dd><dt><span class="term"><code class="literal">max_gram</code></span></dt><dd><p class="simpara">Maximum length of characters in a gram.  Defaults to <code class="literal">2</code>.</p><p class="simpara">See <a class="xref" href="max-gram-limits.html" title="Limitations of the max_gram parameter">Limitations of the <code class="literal">max_gram</code> parameter</a>.</p></dd><dt><span class="term"><code class="literal">token_chars</code></span></dt><dd><p class="simpara">Character classes that should be included in a token.  Elasticsearch
will split on characters that don’t belong to the classes specified.
Defaults to <code class="literal">[]</code> (keep all characters).</p><p class="simpara">Character classes may be any of the following:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><code class="literal">letter</code> —      for example <code class="literal">a</code>, <code class="literal">b</code>, <code class="literal">ï</code> or <code class="literal">京</code></li><li class="listitem"><code class="literal">digit</code> —       for example <code class="literal">3</code> or <code class="literal">7</code></li><li class="listitem"><code class="literal">whitespace</code> —  for example <code class="literal">" "</code> or <code class="literal">"\n"</code></li><li class="listitem"><code class="literal">punctuation</code> — for example <code class="literal">!</code> or <code class="literal">"</code></li><li class="listitem"><code class="literal">symbol</code> —      for example <code class="literal">$</code> or <code class="literal">√</code></li><li class="listitem"><code class="literal">custom</code> —      custom characters which need to be set using the
<code class="literal">custom_token_chars</code> setting.</li></ul></div></dd><dt><span class="term"><code class="literal">custom_token_chars</code></span></dt><dd>Custom characters that should be treated as part of a token. For example,
setting this to <code class="literal">+-_</code> will make the tokenizer treat the plus, minus and
underscore sign  as part of a token.</dd></dl></div></div><div class="navfooter"><span class="prev"><a href="analysis-classic-tokenizer.html">
              « 
              Classic Tokenizer</a>
           
        </span><span class="next">
           
          <a href="max-gram-limits.html">Limitations of the <code class="literal">max_gram</code> parameter
               »
            </a></span></div></body></html>
