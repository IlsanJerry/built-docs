<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Letter Tokenizer
        | Elasticsearch Reference [2.3]
      | Elastic
    </title><link rel="home" href="index.html" title="Elasticsearch Reference [2.3]" /><link rel="up" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="prev" href="analysis-keyword-tokenizer.html" title="Keyword Tokenizer" /><link rel="next" href="analysis-lowercase-tokenizer.html" title="Lowercase Tokenizer" /><meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/2.3" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="2.3" /><meta name="robots" content="noindex,nofollow" /></head><body><div class="page_header">You are looking at documentation for an older release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference
      [2.3]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span> » <span class="breadcrumb-node">Letter Tokenizer</span></div><div class="navheader"><span class="prev"><a href="analysis-keyword-tokenizer.html">
              « 
              Keyword Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-lowercase-tokenizer.html">Lowercase Tokenizer
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-letter-tokenizer"></a>Letter Tokenizer<a href="https://github.com/elastic/elasticsearch/edit/2.3/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>A tokenizer of type <code class="literal">letter</code> that divides text at non-letters. That’s to
say, it defines tokens as maximal strings of adjacent letters. Note,
this does a decent job for most European languages, but does a terrible
job for some Asian languages, where words are not separated by spaces.</p></div><div class="navfooter"><span class="prev"><a href="analysis-keyword-tokenizer.html">
              « 
              Keyword Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-lowercase-tokenizer.html">Lowercase Tokenizer
               »
            </a></span></div></body></html>
