<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Normalization Token Filter
        | Reference [0.90]
      | Elastic
    </title><link rel="home" href="index.html" title="Reference [0.90]" /><link rel="up" href="analysis-tokenfilters.html" title="Token Filters" /><link rel="prev" href="analysis-common-grams-tokenfilter.html" title="Common Grams Token Filter" /><link rel="next" href="analysis-keep-words-tokenfilter.html" title="Keep Words Token Filter" /><meta name="DC.type" content="Learn/Docs/Elasticsearch/Reference/0.90" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="0.90" /><meta name="robots" content="noindex,nofollow" /></head><body><div class="page_header">You are looking at documentation for an older release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Reference
      [0.90]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenfilters.html">Token Filters</a></span> » <span class="breadcrumb-node">Normalization Token Filter</span></div><div class="navheader"><span class="prev"><a href="analysis-common-grams-tokenfilter.html">
              « 
              Common Grams Token Filter</a>
           
        </span><span class="next">
           
          <a href="analysis-keep-words-tokenfilter.html">Keep Words Token Filter
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-normalization-tokenfilter"></a>Normalization Token Filter<a href="https://github.com/elastic/elasticsearch/edit/0.90/docs/reference/analysis/tokenfilters/normalization-tokenfilter.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>There are several token filters available which try to normalize special
characters of a certain language.</p><p>You can currently choose between <code class="literal">arabic_normalization</code> and
<code class="literal">persian_normalization</code> normalization in your token filter
configuration. For more information check the
<a class="ulink" href="http://lucene.apache.org/core/4_3_1/analyzers-common/org/apache/lucene/analysis/ar/ArabicNormalizer.html" target="_top">ArabicNormalizer</a>
or the
<a class="ulink" href="http://lucene.apache.org/core/4_3_1/analyzers-common/org/apache/lucene/analysis/fa/PersianNormalizer.html" target="_top">PersianNormalizer</a>
documentation.</p><p><span class="strong strong"><strong>Note:</strong></span> These filters are available since <code class="literal">0.90.2</code></p></div><div class="navfooter"><span class="prev"><a href="analysis-common-grams-tokenfilter.html">
              « 
              Common Grams Token Filter</a>
           
        </span><span class="next">
           
          <a href="analysis-keep-words-tokenfilter.html">Keep Words Token Filter
               »
            </a></span></div></body></html>
