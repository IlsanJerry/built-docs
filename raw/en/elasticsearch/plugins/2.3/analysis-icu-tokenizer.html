<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>ICU Tokenizer
        | Elasticsearch Plugins and Integrations [2.3]
      | Elastic
    </title><link rel="home" href="index.html" title="Elasticsearch Plugins and Integrations [2.3]" /><link rel="up" href="analysis-icu.html" title="ICU Analysis Plugin" /><link rel="prev" href="analysis-icu-normalization-charfilter.html" title="ICU Normalization Character Filter" /><link rel="next" href="analysis-icu-normalization.html" title="ICU Normalization Token Filter" /><meta name="DC.type" content="Learn/Docs/Elasticsearch/Plugins/2.3" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="2.3" /><meta name="robots" content="noindex,nofollow" /></head><body><div class="page_header">You are looking at documentation for an older release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Plugins and Integrations
      [2.3]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis Plugins</a></span> » <span class="breadcrumb-link"><a href="analysis-icu.html">ICU Analysis Plugin</a></span> » <span class="breadcrumb-node">ICU Tokenizer</span></div><div class="navheader"><span class="prev"><a href="analysis-icu-normalization-charfilter.html">
              « 
              ICU Normalization Character Filter</a>
           
        </span><span class="next">
           
          <a href="analysis-icu-normalization.html">ICU Normalization Token Filter
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="analysis-icu-tokenizer"></a>ICU Tokenizer<a href="https://github.com/elastic/elasticsearch/edit/2.3/docs/plugins/analysis-icu.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>Tokenizes text into words on word boundaries, as defined in
<a class="ulink" href="http://www.unicode.org/reports/tr29/" target="_top">UAX #29: Unicode Text Segmentation</a>.
It behaves much like the <a class="ulink" href="/guide/en/elasticsearch/reference/2.3/analysis-standard-tokenizer.html" target="_top"><code class="literal">standard</code> tokenizer</a>,
but adds better support for some Asian languages by using a dictionary-based
approach to identify words in Thai, Lao, Chinese, Japanese, and Korean, and
using custom rules to break Myanmar and Khmer text into syllables.</p><div class="pre_wrapper lang-sense"><pre class="programlisting prettyprint lang-sense">PUT icu_sample
{
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "my_icu_analyzer": {
            "tokenizer": "icu_tokenizer"
          }
        }
      }
    }
  }
}</pre></div><div class="sense_widget" data-snippet="snippets/4.sense"></div></div><div class="navfooter"><span class="prev"><a href="analysis-icu-normalization-charfilter.html">
              « 
              ICU Normalization Character Filter</a>
           
        </span><span class="next">
           
          <a href="analysis-icu-normalization.html">ICU Normalization Token Filter
               »
            </a></span></div></body></html>
