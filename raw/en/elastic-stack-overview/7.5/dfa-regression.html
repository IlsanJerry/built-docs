<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Regression
        | Elastic Stack Overview [7.5]
      | Elastic
    </title><link rel="home" href="index.html" title="Elastic Stack Overview [7.5]" /><link rel="up" href="ml-dfa-concepts.html" title="Concepts" /><link rel="prev" href="dfa-outlier-detection.html" title="Outlier detection" /><link rel="next" href="ml-dfanalytics-evaluate.html" title="Evaluating data frame analytics" /><meta name="DC.type" content="Learn/Docs/Elastic Stack/Overview/7.5" /><meta name="DC.subject" content="Elastic Stack" /><meta name="DC.identifier" content="7.5" /></head><body><div class="page_header">You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elastic Stack Overview
      [7.5]
    </a></span> » <span class="breadcrumb-link"><a href="ml-dfanalytics.html">Machine learning data frame analytics</a></span> » <span class="breadcrumb-link"><a href="ml-dfa-concepts.html">Concepts</a></span> » <span class="breadcrumb-node">Regression</span></div><div class="navheader"><span class="prev"><a href="dfa-outlier-detection.html">
              « 
              Outlier detection</a>
           
        </span><span class="next">
           
          <a href="ml-dfanalytics-evaluate.html">Evaluating data frame analytics
               »
            </a></span></div><div class="xpack section"><div class="titlepage"><div><div><h2 class="title"><a id="dfa-regression"></a>Regression<a href="https://github.com/elastic/stack-docs/edit/7.5/docs/en/stack/ml/df-analytics/dfa-regression.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a><a class="xpack_tag" href="/subscriptions"></a></h2></div></div></div><div class="warning admon"><div class="icon"></div><div class="admon_content"><p>This functionality is experimental and may be changed or removed completely in a future release. Elastic will take a best effort approach to fix any issues, but experimental features are not subject to the support SLA of official GA features.</p></div></div><p>Regression analysis is a machine learning process for estimating the relationships among
different fields in your data, then making further predictions based on these
relationships.</p><p>For example, suppose we are interested in finding the relationship between
apartment size and monthly rent in a city. Our imaginary dataset consists of
three data points:</p><div class="informaltable"><table cellpadding="4px" border="1"><colgroup><col class="col_1" /><col class="col_2" /></colgroup><tbody><tr><td align="left" valign="top"><p>Size (m2)</p></td><td align="left" valign="top"><p>Monthly rent</p></td></tr><tr><td align="left" valign="top"><p>44</p></td><td align="left" valign="top"><p>1600</p></td></tr><tr><td align="left" valign="top"><p>24</p></td><td align="left" valign="top"><p>1055</p></td></tr><tr><td align="left" valign="top"><p>63</p></td><td align="left" valign="top"><p>2300</p></td></tr></tbody></table></div><p>After the model determines the relationship between the
apartment size and the rent, it can make predictions such as the
monthly rent of a hundred square meter-size apartment.</p><p>This is a simple example. Usually regression problems are multi-dimensional,
so the relationships that regression analysis tries to find are between multiple
fields. To extend our example, a more complex
regression analysis could take into account additional factors such as the location
of the apartment in the city, on which floor it is, and whether the apartment
has a riverside view or not and so on.</p><h4><a id="dfa-regression-features"></a>Feature variables<a href="https://github.com/elastic/stack-docs/edit/7.5/docs/en/stack/ml/df-analytics/dfa-regression.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>When you perform regression analysis, you must identify a subset of fields that you
want to use to create a model for predicting other fields. We refer to these
fields as <span class="emphasis"><em>feature variables</em></span> and <span class="emphasis"><em>dependent variables</em></span>, respectively.
Feature variables are the values that the dependent variable value depends on. If one or
more of the feature variables changes, the dependent variable value also changes. There are
three different types of feature variables that you can use with our regression
algorithm:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Numerical. In our example, the size of the apartment was a
numerical feature variable.</li><li class="listitem">Categorical. A variable that can have one value from a set of values. The
value set has a fixed and limited number of possible items. In the example,
the location of the apartment in the city (borough) is a categorical variable.</li><li class="listitem">Boolean. The riverside view in the example is a boolean value because an
  apartment either has a riverside view or doesn’t have one.
Arrays are not supported.</li></ul></div><h4><a id="dfa-regression-supervised"></a>Training the regression algorithm<a href="https://github.com/elastic/stack-docs/edit/7.5/docs/en/stack/ml/df-analytics/dfa-regression.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Regression is a supervised machine learning process, which means that you
need to supply a labeled training dataset that has some feature variables and a
dependent variable. The regression algorithm learns the relationships between the
feature and the dependent variable. Once you’ve trained the model on your training
dataset, you can reuse the knowledge that the model has learned about the
relationships between the data points to make certain inferences about new data
points.</p><p>The relationships between the feature variables and the dependent variable are described as a
mathematical function. Regression analysis tries to find the best prediction for
the dependent variable by combining the predictions from multiple base learners –
algorithms that generalize from the dataset. The performance of an ensemble is
usually better than the performance of each individual base learner because the
individual learners will make different errors. These average out when their
predictions are combined. The ensemble learning technique that we use in the
Elastic Stack is a type of boosting called extreme gradient boost (XGboost) which
combines decision trees with gradient boosting methodologies.</p><h4><a id="dfa-regression-evaluation"></a>Measuring model performance<a href="https://github.com/elastic/stack-docs/edit/7.5/docs/en/stack/ml/df-analytics/dfa-regression.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>You can measure how well the model has performed on your training dataset by
using the <code class="literal">regression</code> evaluation type of the
<a class="ulink" href="/guide/en/elasticsearch/reference/7.5/evaluate-dfanalytics.html" target="_top">evaluate data frame analytics API</a>. The mean squared
error (MSE) value that the evaluation provides you on the training dataset is
the <span class="emphasis"><em>training error</em></span>. Training the regression model means finding the
combination of model parameters that produces the lowest possible training
error.</p><p>Another crucial measurement is how well your model performs on unseen
data points. To assess how well the trained model will perform on data it has
never seen before, you must set aside a proportion of the training dataset for
testing. This split of the dataset is the testing dataset. Once the model has
been trained, you can let the model
predict the value of the data points it has never seen before and compare the
prediction to the actual value. This test provides an estimate of a quantity
known as the <span class="emphasis"><em>model generalization error</em></span>.</p><p>Two concepts describe how well the regression algorithm was able to learn the
relationship between the feature variables and the dependent variable. <span class="emphasis"><em>Underfitting</em></span> is when
the model cannot capture the complexity of the dataset. <span class="emphasis"><em>Overfitting</em></span> is when
the model is too specific to the training data set and is capturing details
which do not generalize to new data. A model that overfits the data has a
low MSE value on the training dataset and a high MSE value on the testing
dataset. For more information about the evaluation metrics, see
<a class="xref" href="ml-dfanalytics-evaluate.html#ml-dfanalytics-regression-evaluation" title="Regression evaluation">Regression evaluation</a>.</p></div><div class="navfooter"><span class="prev"><a href="dfa-outlier-detection.html">
              « 
              Outlier detection</a>
           
        </span><span class="next">
           
          <a href="ml-dfanalytics-evaluate.html">Evaluating data frame analytics
               »
            </a></span></div></body></html>
