<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title xmlns="">Update strategy
        | Elastic Cloud on Kubernetes [0.9]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elastic Cloud on Kubernetes [0.9]" /><link rel="up" href="k8s-elasticsearch-specification.html" title="Running Elasticsearch on ECK" /><link rel="prev" href="k8s-init-containers-plugin-downloads.html" title="Init containers for plugin downloads" /><link rel="next" href="k8s-group-definitions.html" title="Group definitions" /><meta xmlns="" name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta xmlns="" name="DC.type" content="Learn/Docs/Kubernetes/Reference/0.9" /><meta xmlns="" name="DC.subject" content="ECK" /><meta xmlns="" name="DC.identifier" content="0.9" /></head><body><div xmlns="" class="page_header">You are looking at documentation for an alpha release. Not what you want? See <a href="https://www.elastic.co/elasticsearch-kubernetes">Deploy Elasticsearch & Kibana on Kubernetes</a> documentation.
</div><div xmlns="" class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elastic Cloud on Kubernetes
      [0.9]
    </a></span> » <span class="breadcrumb-link"><a href="k8s-elasticsearch-specification.html">Running Elasticsearch on ECK</a></span> » <span class="breadcrumb-node">Update strategy</span></div><div xmlns="" class="navheader"><span class="prev"><a href="k8s-init-containers-plugin-downloads.html">
              « 
              Init containers for plugin downloads</a>
           
        </span><span class="next">
           
          <a href="k8s-group-definitions.html">Group definitions
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="k8s-update-strategy"></a>Update strategy<a xmlns="" href="https://github.com/elastic/cloud-on-k8s/edit/0.9/docs/elasticsearch-spec.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>The Elasticsearch cluster configuration can be updated at any time to:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Add new nodes</li><li class="listitem">Remove some nodes</li><li class="listitem">Change Elasticsearch configuration</li><li class="listitem">Change Pod resources (memory limits, cpu limit, environment variables, etc.)</li></ul></div><p>On any change, ECK reconciles Kubernetes resources towards the desired cluster definition. Changes occur in a rolling fashion: the state of the cluster is continuously monitored, to allow addition of new nodes and removal of deprecated nodes.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="k8s-change-budget"></a>Change budget<a xmlns="" href="https://github.com/elastic/cloud-on-k8s/edit/0.9/docs/elasticsearch-spec.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3></div></div></div><p>No downtime should be expected when the cluster topology changes. Shards on deprecated nodes are migrated away so the node can be safely removed.</p><p>For example, to mutate a 3-nodes cluster with 16GB memory limit on each node to a 3-nodes cluster with 32GB memory limit on each node, ECK will:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">Add a new 32GB node: the cluster temporarily has 4 nodes</li><li class="listitem">Migrate data away from the first 16GB node</li><li class="listitem">Once data is migrated, remove the first 16GB node</li><li class="listitem">Follow the same steps for the 2 other 16GB nodes</li></ol></div><p>The cluster health stays green during the entire process.
By default, only one extra node can be added on top of the expected ones. In the example above, a 3-nodes cluster may temporarily be composed of 4 nodes while data migration is in progress.</p><p>This behaviour can be controlled through the <code class="literal">changeBudget</code> section of the cluster specification <code class="literal">updateStrategy</code>. If not specified, it defaults to the following:</p><div xmlns="" class="pre_wrapper lang-yaml"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-yaml">spec:
  updateStrategy:
    changeBudget:
      maxSurge: 1
      maxUnavailable: 0</pre></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><code class="literal">maxSurge</code> specifies the number of Pods that can be added to the cluster, on top of the desired number of nodes in the specification during cluster updates</li><li class="listitem"><code class="literal">maxUnavailable</code> specifies the number of Pods that can be made unavailable during cluster updates</li></ul></div><p>The default of <code class="literal">maxSurge: 1; maxUnavailable: 0</code> spins up an additional Elasticsearch node during cluster updates.
It is possible to speed up cluster topology changes by increasing <code class="literal">maxSurge</code>. For example, setting <code class="literal">maxSurge: 3</code> would allow 3 new nodes to be created while the original 3 migrate data in parallel.
The cluster would then temporarily have 6 nodes.</p><p>Setting <code class="literal">maxSurge</code> to 0 and <code class="literal">maxUnavailable</code> to a positive value only allows a maximum number of Pods to exist on the Kubernetes cluster.
For example, <code class="literal">maxSurge: 0; maxUnavailable: 1</code> would perform the 3 nodes upgrade this way:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">Migrate data away from the first 16GB node</li><li class="listitem">Once data is migrated, remove the 16GB node: the cluster temporarily has 2 nodes</li><li class="listitem">Add a new 32GB node: the cluster grows to 3 nodes</li><li class="listitem">Follow the same steps for the 2 other 16GB nodes</li></ol></div><p>Even if a <code class="literal">changeBudget</code> is specified, ECK makes sure that some invariants are maintained while a mutation is in progress. In the cluster, there must be at least:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">One master node alive</li><li class="listitem">One data node alive</li></ul></div><p>So under certain circumstances ECK ignores the change budget. For example, a safe migration from a 1-node cluster to another 1-node cluster can only be done by temporarily setting up a 2-nodes cluster.</p><p>It is possible to configure the <code class="literal">changeBudget</code> to optimize the reuse of persistent volumes, instead of migrating data across nodes. This feature is not supported yet, more details to come in the next release.</p></div></div><div xmlns="" class="navfooter"><span class="prev"><a href="k8s-init-containers-plugin-downloads.html">
              « 
              Init containers for plugin downloads</a>
           
        </span><span class="next">
           
          <a href="k8s-group-definitions.html">Group definitions
               »
            </a></span></div></body></html>