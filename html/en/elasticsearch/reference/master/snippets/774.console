GET /_analyze
{
  "tokenizer" : "whitespace",
  "filter" : [
    "common_grams", {
      "type": "common_grams",
      "common_words": ["is", "the"]
    }
  ],
  "text" : "the quick fox is brown"
}
