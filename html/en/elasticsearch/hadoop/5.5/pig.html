<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Apache Pig support
        | Elasticsearch for Apache Hadoop [5.5]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch for Apache Hadoop [5.5]" /><link rel="up" href="reference.html" title="Elasticsearch for Apache Hadoop" /><link rel="prev" href="hive.html" title="Apache Hive integration" /><link rel="next" href="spark.html" title="Apache Spark support" /><meta name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta name="DC.type" content="Learn/Docs/Elasticsearch/Apache Hadoop/5.5" /><meta name="DC.subject" content="Elasticsearch" /><meta name="DC.identifier" content="5.5" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#ffffff">
    <meta name="apple-mobile-web-app-title" content="Elastic">
    <meta name="application-name" content="Elastic">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">
    <meta name="naver-site-verification" content="936882c1853b701b3cef3721758d80535413dbfd" />
    <meta name="yandex-verification" content="d8a47e95d0972434" />
    <meta name="description" content="" />
    <meta name="localized" content="true" />
    <meta property="og:image" content="https://www.elastic.co/static/images/elastic-logo-200.png" />
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <!-- For third-generation iPad with high-resolution Retina display: -->
    <link rel="apple-touch-icon-precomposed" sizes="64x64" href="/favicon_64x64_16bit.png">
    <!-- For iPhone with high-resolution Retina display: -->
    <link rel="apple-touch-icon-precomposed" sizes="32x32" href="/favicon_32x32.png">
    <!-- For first- and second-generation iPad: -->
    <link rel="apple-touch-icon-precomposed" sizes="16x16" href="/favicon_16x16.png">
    <!-- css -->
    <script src="/static/js/jquery.min.js"></script>
    <script src="/static/js/bootstrap.min.js"></script>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet" type="text/css" href="/guide/static/styles.css" />
  </head>

  <body>
    <!-- Google Tag Manager -->
    <script>dataLayer = [];</script><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-58RLH5" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-58RLH5');</script>
    <!-- End Google Tag Manager -->
    
    <!-- new ga for staging server -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12395217-16"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-12395217-16');
    </script>
    <!-- new ga for staging server -->

    <!-- Elastic APM -->
    <!--
    <script src="https://www.elastic.co/static/js/elastic-apm-js-base.umd.min.2.2.0.js"></script>
    <script type="text/javascript">
      var elasticApm = init({
        serviceName: 'elastic-co-frontend',
        serverUrl: 'https://3ddd1ee09cc242c4b169d36f5a2b8b77.apm.us-west1.gcp.cloud.es.io:443',
        stackTraceLimit: 5,
        serviceVersion: '1.0.0'
      })
    
      var pageLoadName
      var pathname = window.location.pathname.replace(/\/es|\/pt|\/jp|\/pt|\/fr|\/kr|\/cn|\/de/g, '')
      var parts = pathname.split('/');
    
      if (parts.length && parts[1] === 'blog') {
        if (parts.length === 2) {
          pageLoadName =  '/blog';
        }
        else if (parts[2] === 'category') {
          pageLoadName =  '/blog/category';
        }
        else if (parts[2] === 'archive') {
          pageLoadName =  '/blog/archive';
        }
        else {
          pageLoadName =  '/blog/detail';
        }
      }
      else if (parts.length && parts[1] === 'elasticon') {
        if (parts.length === 2) {
          pageLoadName =  '/elasticon';
        }
        else if (parts.length === 5 && (parts[2] === 'conf' || parts[2] === 'tour')) {
          pageLoadName =  '/elasticon/overview';
        }
        else if (parts.length > 5 && (parts[2] === 'conf' || parts[2] === 'tour')) {
          pageLoadName =  '/elasticon/video';
        }
      }
      else if (parts.length && parts[1] === 'guide') {
        pageLoadName =  '/guide';
      }
      else if (parts.length === 2 && parts[1] === 'videos') {
        pageLoadName =  '/videos';
      }
      else if (parts.length > 2 && parts[1] === 'videos') {
        pageLoadName =  '/videos/detail';
      }
      else if (parts.length > 2 && parts[1] === 'webinars') {
        pageLoadName =  '/webinars/detail';
      }
      else {
        pageLoadName =  window.location.pathname;
      }
    
      console.log('apm pageLoadName:', pageLoadName, parts)
      elasticApm.setTags({env:"production"});
      elasticApm.setInitialPageLoadName(pageLoadName);
    </script>
    -->

    <!-- Header Section -->
    
    <div id='elastic-nav'></div>

    <!-- Subnav -->
    <div>
      <div>
        <div class="tertiary-nav d-none d-md-block">
          <div class="container">
            <div class="p-t-b-15 d-flex justify-content-between nav-container">
              <div class="breadcrum-wrapper"><span><a href="/guide/" style="font-size: 14px; font-weight: 600; color: #000;">Docs</a></span></div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="main-container">
      <section id="content" >
        <div class="content-wrapper">

          <section id="guide" lang="en">
            <div class="container">
              <div class="row">
                <div class="col-xs-12 col-sm-8 col-md-8 guide-section">
                  <!-- start body -->
                  <div class="page_header">You are looking at documentation for an older release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch for Apache Hadoop
      [5.5]
    </a></span> » <span class="breadcrumb-link"><a href="reference.html">Elasticsearch for Apache Hadoop</a></span> » <span class="breadcrumb-node">Apache Pig support</span></div><div class="navheader"><span class="prev"><a href="hive.html">
              « 
              Apache Hive integration</a>
           
        </span><span class="next">
           
          <a href="spark.html">Apache Spark support
               »
            </a></span></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a id="pig"></a>Apache Pig support<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><div class="blockquote"><table border="0" class="blockquote" summary="Block quote"><tr><td width="10%" valign="top"> </td><td width="80%" valign="top"><p><a class="ulink" href="http://pig.apache.org/" target="_top">Apache Pig</a> is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs.</p></td><td width="10%" valign="top"> </td></tr><tr><td width="10%" valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">
Pig website
</span></td></tr></table></div><p>It provides a high-level, powerful, <span class="emphasis"><em>scripting</em></span>-like transformation language which gets compiled into Map/Reduce jobs at runtime by the Pig <span class="emphasis"><em>compiler</em></span>. To simplify working with arbitrary data, Pig associates a <span class="emphasis"><em>schema</em></span> (or type information) with each data set for validation and performance. This in turn, breaks it down into <span class="emphasis"><em>discrete</em></span> data types that can be transformed through various operators or custom functions (or <a class="ulink" href="http://pig.apache.org/docs/r0.12.1/udf.html" target="_top">UDF</a>s). Data can be loaded from and stored to various storages such as the local file-system or HDFS, and with elasticsearch-hadoop into Elasticsearch as well.</p><h3><a id="pig-installation"></a>Installation<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>In order to use elasticsearch-hadoop, its jar needs to be in Pig’s classpath. There are various ways of making that happen though typically the <a class="ulink" href="http://pig.apache.org/docs/r0.12.1/basic.html#register" target="_top">REGISTER</a> command is used:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">REGISTER /path/elasticsearch-hadoop.jar;</pre></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>The command expects a proper URI that can be found either on the local file-system or remotely. Typically it’s best to use a distributed file-system (like HDFS or Amazon S3) and use that since the script might be executed
on various machines.</p></div></div><p>As an alternative, when using the command-line, one can register additional jars through the <code class="literal">-Dpig.additional.jars</code> option (that accepts an URI as well):</p><div class="pre_wrapper lang-bash"><pre class="programlisting prettyprint lang-bash">$ pig -Dpig.additional.jars=/path/elasticsearch-hadoop.jar:&lt;other.jars&gt; script.pig</pre></div><p>or if the jars are on HDFS</p><div class="pre_wrapper lang-bash"><pre class="programlisting prettyprint lang-bash">$ pig \
-Dpig.additional.jars=hdfs://&lt;cluster-name&gt;:&lt;cluster-port&gt;/&lt;path&gt;/elasticsearch-hadoop.jar:&lt;other.jars&gt; script.pig</pre></div><h3><a id="pig-configuration"></a>Configuration<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>With Pig, one can specify the <a class="link" href="configuration.html" title="Configuration">configuration</a> properties (as an alternative to Hadoop <code class="literal">Configuration</code> object) as a constructor parameter when declaring <code class="literal">EsStorage</code>:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">STORE B INTO 'radio/artists' <a id="CO35-1"></a><i class="conum" data-value="1"></i>
       USING org.elasticsearch.hadoop.pig.EsStorage
             ('es.http.timeout = 5m', <a id="CO35-2"></a><i class="conum" data-value="2"></i>
              'es.index.auto.create = false'); <a id="CO35-3"></a><i class="conum" data-value="3"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO35-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>elasticsearch-hadoop configuration (target resource)</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO35-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>elasticsearch-hadoop option (http timeout)</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO35-3"><i class="conum" data-value="3"></i></a> </p></td><td valign="top" align="left"><p>another elasticsearch-hadoop configuration (disable automatic index creation)</p></td></tr></table></div><div class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p>To avoid having to specify the fully qualified class name (<code class="literal">org.elasticsearch.hadoop.pig.EsStorage</code>), consider using a shortcut through <a class="ulink" href="http://pig.apache.org/docs/r0.11.1/basic.html#define" target="_top"><code class="literal">DEFINE</code></a> command:</p></div></div><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage();</pre></div><p>Do note that it is possible (and recommended) to specify the configuration parameters to reduce script duplication, such as <code class="literal">es.query</code> or <code class="literal">es.mapping.names</code>:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage('my.cfg.param=value');</pre></div><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>Pig definitions are replaced as are; even though the syntax allows <span class="emphasis"><em>parametrization</em></span>, Pig will silently ignore any parameters outside the <code class="literal">DEFINE</code> declaration.</p></div></div><h4><a id="tuple-names"></a>Tuple field names<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>Among the <a class="ulink" href="http://pig.apache.org/docs/r0.12.1/basic.html#data-types" target="_top">various types</a> available in Pig, <code class="literal">tuple</code>s are used the most. Tuples are defined as <span class="quote">“<span class="quote">ordered sets of fields</span>”</span> (e.g. <code class="literal">(19,2)</code>) however structurally they are shaped
as ordered <span class="emphasis"><em>maps</em></span> since each field has a name, which may be defined or not (e.g. <code class="literal">(field:19, another:2)</code>). The <span class="emphasis"><em>ordered</em></span> aspect is important and forces elasticsearch-hadoop to use JSON arrays for tuples  (using JSON objects is not an option as it does not preserve ordering besides the fact that it requires keys/names which might be or not available in a tuple).
Obeying the rule of <a class="ulink" href="http://en.wikipedia.org/wiki/Principle_of_least_astonishment" target="_top">least surprise</a>, elasticsearch-hadoop by default will <span class="emphasis"><em>disregard</em></span> a tuple’s field names, both when writing and reading.</p><p>To change this behavior (which in effect means treating tuples as arrays of maps instead of arrays), use the boolean property <code class="literal">es.mapping.pig.tuple.use.field.names</code> (by default <code class="literal">false</code>) and set it to <code class="literal">true</code>.</p><p>The table below illustrates the difference between the two settings:</p><div class="informaltable"><table cellpadding="4px" border="1"><colgroup><col class="col_1" /><col class="col_2" /><col class="col_3" /></colgroup><thead><tr><th align="center" valign="top">Tuple schema</th><th align="center" valign="top">Tuple value</th><th align="center" valign="top">Resulting JSON representation</th></tr></thead><tbody><tr><td colspan="3" align="center" valign="top"><p><span class="strong strong"><strong><code class="literal">es.mapping.pig.tuple.use.field.names</code> <span class="strong strong"><strong><code class="literal">false</code></strong></span> (default)</strong></span></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">(foo: (nr:int, name:chararray))</code></p></td><td align="center" valign="top"><p><code class="literal">(1,"kimchy")</code></p></td><td align="center" valign="top"><p><code class="literal">{"foo":[1, "kimchy"]}</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">(bar: (int, chararray))</code></p></td><td align="center" valign="top"><p><code class="literal">(1,"kimchy")</code></p></td><td align="center" valign="top"><p><code class="literal">{"bar":[1, "kimchy"]}</code></p></td></tr><tr><td colspan="3" align="center" valign="top"><p><span class="strong strong"><strong><code class="literal">es.mapping.pig.tuple.use.field.names</code> <span class="strong strong"><strong><code class="literal">true</code></strong></span></strong></span></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">(foo: (nr:int, name:chararray))</code></p></td><td align="center" valign="top"><p><code class="literal">(1,"kimchy")</code></p></td><td align="center" valign="top"><p><code class="literal">{"foo":[{"nr":1, "name":"kimchy"}]}</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">(bar: (int, chararray))</code></p></td><td align="center" valign="top"><p><code class="literal">(1,"kimchy")</code></p></td><td align="center" valign="top"><p><code class="literal">{"bar":[{"val_0":1, "val_1":"name"}]}</code></p></td></tr></tbody></table></div><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>When using tuples, it is <span class="emphasis"><em>highly</em></span> recommended to create the index mapping before-hand as it is quite common for tuples to contain mixed types (numbers, strings, other tuples, etc…​) which, when mapped as an array (the default) can cause parsing errors (as the automatic mapping can infer the fields to be numbers instead of strings, etc…​). In fact, the example above falls in this category since the tuple contains both a number (<code class="literal">1</code>) and a string (<code class="literal">"kimchy"</code>), which will the auto-detection to map both <code class="literal">foo</code> and <code class="literal">bar</code> as a number and thus causing an exception when encountering <code class="literal">"kimchy"</code>. Please refer to <a class="link" href="mapping.html#auto-mapping-type-loss">this</a> for more information.
Additionally consider <code class="literal">breaking</code>/<code class="literal">flatten</code>ing the tuple into primitive/data atoms before sending the data off to Elasticsearch.</p></div></div><h4><a id="handling-splits"></a>Reducers parallelism<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>By default, Pig will only use one reducer per job which in most cases is inefficient.  To address these issue:</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Use the Parallel Features</span></dt><dd>As explained in the <a class="ulink" href="http://pig.apache.org/docs/r0.13.0/perf.html#parallel" target="_top">reference docs</a>, out of the box Pig expects each reducer to process about 1 GB of data; unfortunately if the data is scattered
around the network this becomes inefficient as the entire job is effectively serialized. Change this by increasing the number of reducers to map that of your shards through the <code class="literal">default_parallel</code> property or <code class="literal">PARALLEL</code> keyword:</dd></dl></div><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">-- launch the Map/Reduce job with 5 reducers
SET default_parallel 5;</pre></div><p>or by using the <code class="literal">PARALLEL</code> keyword with <code class="literal">COGROUP</code>, <code class="literal">CROSS</code>, <code class="literal">DISTINCT</code>, <code class="literal">GROUP</code>, <code class="literal">JOIN</code>(inner), <code class="literal">JOIN</code>(outer) and <code class="literal">ORDER BY</code>.</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">B = GROUP A BY t PARALLEL 18;</pre></div><div class="variablelist"><dl class="variablelist"><dt><span class="term">Disable split combination</span></dt><dd>Out of the box Pig over-eagerly <a class="ulink" href="https://pig.apache.org/docs/r0.13.0/perf.html#combine-files" target="_top">combines its input splits</a> even if it does not know how big they are. This again kills parallelism since it serializes the queries to Elasticsearch ; typically this looks as follows
in the logs:</dd></dl></div><div class="pre_wrapper lang-bash"><pre class="programlisting prettyprint lang-bash">20yy-mm-dd hh:mm:ss,mss [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 25
20yy-mm-dd hh:mm:ss,mss [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1</pre></div><p>Avoid this by setting <code class="literal">pig.noSplitCombination</code> to <code class="literal">true</code> (one can also use <code class="literal">pig.splitCombination</code> to <code class="literal">false</code> however we recommend the former) either by setting the property before invoking the script:</p><div class="pre_wrapper lang-bash"><pre class="programlisting prettyprint lang-bash">pig -Dpig.noSplitCombination=true myScript.pig</pre></div><p>in the Pig script itself:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">SET pig.noSplitCombination TRUE;</pre></div><p>or through the global <code class="literal">pig.properties</code> configuration in your Pig install:</p><div class="pre_wrapper lang-properties"><pre class="programlisting prettyprint lang-properties">pig.noSplitCombination=true</pre></div><p>Unfortunately elasticsearch-hadoop cannot set these properties automatically so the user has to do that manually per script or making them global through the Pig configuration as described above.</p><h3><a id="pig-alias"></a>Mapping<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>Out of the box, elasticsearch-hadoop uses the Pig schema to map the data in Elasticsearch, using both the field names and types in the process. There are cases however when the names in Pig cannot
be used with Elasticsearch (invalid characters, existing names with different layout, etc…​). For such cases, one can use the <code class="literal">es.mapping.names</code> setting which accepts a comma-separated list of mapped names in the following format: <code class="literal">Pig field name</code> : <code class="literal">Elasticsearch field name</code></p><p>For example:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">STORE B INTO  '...' USING org.elasticsearch.hadoop.pig.EsStorage(
    'es.mapping.names=date:@timestamp, uRL:url')         <a id="CO36-1"></a><i class="conum" data-value="1"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO36-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Pig column <code class="literal">date</code> mapped in Elasticsearch to <code class="literal">@timestamp</code>; Pig column <code class="literal">uRL</code> mapped in Elasticsearch to <code class="literal">url</code></p></td></tr></table></div><div class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p>Since elasticsearch-hadoop 2.1, the Pig schema case sensitivity is preserved to Elasticsearch and back.</p></div></div><h3><a id="_writing_data_to_elasticsearch_3"></a>Writing data to Elasticsearch<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>Elasticsearch is exposed as a native <code class="literal">Storage</code> to Pig so it can be used to store data into it:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">-- load data from HDFS into Pig using a schema
A = LOAD 'src/test/resources/artists.dat' USING PigStorage()
                    AS (id:long, name, url:chararray, picture: chararray);
-- transform data
B = FOREACH A GENERATE name, TOTUPLE(url, picture) AS links;
-- save the result to Elasticsearch
STORE B INTO 'radio/artists'<a id="CO37-1"></a><i class="conum" data-value="1"></i>
       USING org.elasticsearch.hadoop.pig.EsStorage(); <a id="CO37-2"></a><i class="conum" data-value="2"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO37-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Elasticsearch resource (index and type) associated with the given storage</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO37-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>additional configuration parameters can be passed inside the <code class="literal">()</code> - in this
case the defaults are used</p></td></tr></table></div><p>For cases where the id (or other metadata fields like <code class="literal">ttl</code> or <code class="literal">timestamp</code>) of the document needs to be specified, one can do so by setting the appropriate <a class="link" href="configuration.html#cfg-mapping" title="Mapping (when writing to Elasticsearch)">mapping</a>, namely <code class="literal">es.mapping.id</code>. Following the previous example, to indicate to Elasticsearch to use the field <code class="literal">id</code> as the document id, update the <code class="literal">Storage</code> configuration:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">STORE B INTO 'radio/artists USING org.elasticsearch.hadoop.pig.EsStorage('es.mapping.id=id'...);</pre></div><h4><a id="_writing_existing_json_to_elasticsearch_2"></a>Writing existing JSON to Elasticsearch<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>When the job input data is already in JSON, elasticsearch-hadoop allows direct indexing <span class="emphasis"><em>without</em></span> applying any transformation; the data is taken as is and sent directly to Elasticsearch. In such cases, one needs to indicate the json input by setting
the <code class="literal">es.input.json</code> parameter. As such, in this case elasticsearch-hadoop expects to receive a tuple with a single field (representing the JSON document); the library will recognize common <span class="emphasis"><em>textual</em></span> types such as <code class="literal">chararray</code> or <code class="literal">bytearray</code> otherwise it just calls <code class="literal">toString</code> to get a hold of the JSON content.</p><div class="table"><a id="id-1.3.15.56"></a><p class="title"><strong>Table 4. Pig types to use for JSON representation</strong></p><div class="table-contents"><table summary="Pig types to use for JSON representation" cellpadding="4px" border="1"><colgroup><col class="col_1" /><col class="col_2" /></colgroup><thead><tr><th align="center" valign="top"><code class="literal">Pig type</code></th><th align="center" valign="top">Comment</th></tr></thead><tbody><tr><td align="center" valign="top"><p><code class="literal">bytearray</code></p></td><td align="center" valign="top"><p>use this when the JSON data is represented as a <code class="literal">byte[]</code> or similar</p></td></tr><tr><td align="center" valign="top"><p><code class="literal">chararray</code></p></td><td align="center" valign="top"><p>use this if the JSON data is represented as a <code class="literal">String</code></p></td></tr><tr><td align="center" valign="top"><p><span class="emphasis"><em>anything else</em></span></p></td><td align="center" valign="top"><p>make sure the <code class="literal">toString()</code> returns the desired JSON document</p></td></tr></tbody></table></div></div><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>Make sure the data is properly encoded, in <code class="literal">UTF-8</code>. The field content is considered the final form of the document sent to Elasticsearch.</p></div></div><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">A = LOAD '/resources/artists.json' USING PigStorage() AS (json:chararray);" <a id="CO38-1"></a><i class="conum" data-value="1"></i>
STORE B INTO 'radio/artists'
    USING org.elasticsearch.hadoop.pig.EsStorage('es.input.json=true'...); <a id="CO38-2"></a><i class="conum" data-value="2"></i></pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO38-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Load the (JSON) data as a single field (<code class="literal">json</code>)</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO38-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>Indicate the input is of type JSON.</p></td></tr></table></div><h4><a id="_writing_to_dynamicmulti_resources_3"></a>Writing to dynamic/multi-resources<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h4><p>One can index the data to a different resource, depending on the <span class="emphasis"><em>row</em></span> being read, by using patterns. Reusing the aforementioned <a class="link" href="configuration.html#cfg-multi-writes" title="Dynamic/multi resource writes">media example</a>, one could configure it as follows:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">A = LOAD 'src/test/resources/media.dat' USING PigStorage()
            AS (name:chararray, type:chararray, year: chararray); <a id="CO39-1"></a><i class="conum" data-value="1"></i>
STORE B INTO 'my-collection/{type}' <a id="CO39-2"></a><i class="conum" data-value="2"></i>
       USING org.elasticsearch.hadoop.pig.EsStorage();</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO39-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Tuple field used by the resource pattern. Any of the declared fields can be used.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO39-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>Resource pattern using field <code class="literal">type</code> - note the pattern can be used <span class="emphasis"><em>anywhere</em></span> in the resource (on the index, on the type, in both places, etc…​)</p></td></tr></table></div><p>For each tuple about to be written, elasticsearch-hadoop will extract the <code class="literal">type</code> field and use its value to determine the target resource.</p><p>The functionality is also available when dealing with raw JSON - in this case, the value will be extracted from the JSON document itself. Assuming the JSON source contains documents with the following structure:</p><div class="pre_wrapper lang-js"><pre class="programlisting prettyprint lang-js">{
    "media_type":"game",<a id="CO40-1"></a><i class="conum" data-value="1"></i>
    "title":"Final Fantasy VI",
    "year":"1994"
}</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO40-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>field within the JSON document that will be used by the pattern</p></td></tr></table></div><p>the table declaration can be as follows:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">A = LOAD '/resources/media.json' USING PigStorage() AS (json:chararray);" <a id="CO41-1"></a><i class="conum" data-value="1"></i>
STORE B INTO 'my-collection/{media_type}' <a id="CO41-2"></a><i class="conum" data-value="2"></i>
    USING org.elasticsearch.hadoop.pig.EsStorage('es.input.json=true');</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Schema declaration for the tuple. Since JSON input is used, the schema is simply a holder to the raw data</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO41-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>Resource pattern relying on fields <span class="emphasis"><em>within</em></span> the JSON document and <span class="emphasis"><em>not</em></span> on the table schema</p></td></tr></table></div><h3><a id="_reading_data_from_elasticsearch_3"></a>Reading data from Elasticsearch<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>As you would expect, loading the data is straight forward:</p><div class="pre_wrapper lang-sql"><pre class="programlisting prettyprint lang-sql">-- execute Elasticsearch query and load data into Pig
A = LOAD 'radio/artists' <a id="CO42-1"></a><i class="conum" data-value="1"></i>
    USING org.elasticsearch.hadoop.pig.EsStorage('es.query=?me*'); <a id="CO42-2"></a><i class="conum" data-value="2"></i>
DUMP A;</pre></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO42-1"><i class="conum" data-value="1"></i></a> </p></td><td valign="top" align="left"><p>Elasticsearch resource</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO42-2"><i class="conum" data-value="2"></i></a> </p></td><td valign="top" align="left"><p>search query to execute</p></td></tr></table></div><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>Due to a <a class="ulink" href="https://issues.apache.org/jira/browse/PIG-3646" target="_top">bug</a> in Pig, <code class="literal">LoadFunctions</code> are not aware of any schema associated with them. This means <code class="literal">EsStorage</code> is forced to fully parse the documents
from Elasticsearch before passing the data to Pig for projection. In practice, this has little impact as long as a document top-level fields are used; for nested fields consider extracting the values
yourself in Pig.</p></div></div><h3><a id="_reading_data_from_elasticsearch_as_json"></a>Reading data from Elasticsearch as JSON<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>In the case where the results from Elasticsearch need to be in JSON format (typically to be sent down the wire to some other system), one can instruct elasticsearch-hadoop to return the data as is. By setting <code class="literal">es.output.json</code> to <code class="literal">true</code>, the connector will parse the response from Elasticsearch, identify the documents and, without converting them, return their content to the user as <code class="literal">String/chararray</code> objects.</p><h3><a id="pig-type-conversion"></a>Type conversion<a href="https://github.com/elastic/elasticsearch-hadoop/edit/5.5/docs/src/reference/asciidoc/core/pig.adoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><div class="important admon"><div class="icon"><img alt="Important" src="images/icons/important.png" /></div><div class="admon_content"><p>If automatic index creation is used, please review <a class="link" href="mapping.html#auto-mapping-type-loss">this</a> section for more information.</p></div></div><p>Pig internally uses native java types for most of its types and elasticsearch-hadoop abides to that convention.</p><div class="informaltable"><table cellpadding="4px" border="1"><colgroup><col class="col_1" /><col class="col_2" /></colgroup><thead><tr><th align="center" valign="top">Pig type</th><th align="center" valign="top">Elasticsearch type</th></tr></thead><tbody><tr><td align="center" valign="top"><p><code class="literal">null</code></p></td><td align="center" valign="top"><p><code class="literal">null</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">chararray</code></p></td><td align="center" valign="top"><p><code class="literal">string</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">int</code></p></td><td align="center" valign="top"><p><code class="literal">int</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">long</code></p></td><td align="center" valign="top"><p><code class="literal">long</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">double</code></p></td><td align="center" valign="top"><p><code class="literal">double</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">float</code></p></td><td align="center" valign="top"><p><code class="literal">float</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">bytearray</code></p></td><td align="center" valign="top"><p><code class="literal">binary</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">tuple</code></p></td><td align="center" valign="top"><p><code class="literal">array</code> or <code class="literal">map</code> (depending on <a class="link" href="pig.html#tuple-names" title="Tuple field names">this</a> setting)</p></td></tr><tr><td align="center" valign="top"><p><code class="literal">bag</code></p></td><td align="center" valign="top"><p><code class="literal">array</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">map</code></p></td><td align="center" valign="top"><p><code class="literal">map</code></p></td></tr><tr><td colspan="2" align="center" valign="top"><p><span class="strong strong"><strong>Available in Pig 0.10 or higher</strong></span></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">boolean</code></p></td><td align="center" valign="top"><p><code class="literal">boolean</code></p></td></tr><tr><td colspan="2" align="center" valign="top"><p><span class="strong strong"><strong>Available in Pig 0.11 or higher</strong></span></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">datetime</code></p></td><td align="center" valign="top"><p><code class="literal">date</code></p></td></tr><tr><td colspan="2" align="center" valign="top"><p><span class="strong strong"><strong>Available in Pig 0.12 or higher</strong></span></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">biginteger</code></p></td><td align="center" valign="top"><p><code class="literal">not supported</code></p></td></tr><tr><td align="center" valign="top"><p><code class="literal">bigdecimal</code></p></td><td align="center" valign="top"><p><code class="literal">not supported</code></p></td></tr></tbody></table></div><div class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p>While Elasticsearch understands the Pig types up to version 0.12.1, it is backwards compatible with Pig 0.9</p></div></div><p>It is worth mentioning that rich data types available only in Elasticsearch, such as <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/geo-point.html" target="_top"><code class="literal">GeoPoint</code></a> or <a class="ulink" href="https://www.elastic.co/guide/en/elasticsearch/reference/2.1/geo-shape.html" target="_top"><code class="literal">GeoShape</code></a> are supported by converting their structure into the primitives available in the table above. For example, based on its storage a <code class="literal">geo_point</code> might be
returned as a <code class="literal">chararray</code> or a <code class="literal">tuple</code>.</p></div><div class="navfooter"><span class="prev"><a href="hive.html">
              « 
              Apache Hive integration</a>
           
        </span><span class="next">
           
          <a href="spark.html">Apache Spark support
               »
            </a></span></div>
                  <!-- end body -->
                </div>
                <div class="col-xs-12 col-sm-4 col-md-4" id="right_col">
                  <div id="rtpcontainer" style="display: block;">
                    <div class="mktg-promo">
                      <h3>Getting Started Videos</h3>
                      <ul class="icons">
                        <li class="icon-elasticsearch-white"><a href="https://www.elastic.co/webinars/getting-started-elasticsearch?baymax=default&elektra=docs&storm=top-video">Starting Elasticsearch</a></li>
                        <li class="icon-kibana-white"><a href="https://www.elastic.co/webinars/getting-started-kibana?baymax=default&elektra=docs&storm=top-video">Introduction to Kibana</a></li>
                        <li class="icon-logstash-white"><a href="https://www.elastic.co/webinars/getting-started-logstash?baymax=default&elektra=docs&storm=top-video">Logstash Starter Guide</a></li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>

        </div>


<div id='elastic-footer'></div>
<!-- Footer Section end-->

<script src='https://www.elastic.co/elastic-nav.js'></script>
<script src='https://www.elastic.co/elastic-footer.js'></script>
      </section>
    </div>

    
<script type="text/javascript">
	var suggestionsUrl = "https://search.elastic.co/suggest";
	var localeUrl = '{"relative_url_prefix":"/","code":"en-us","display_code":"en-us","url":"/guide_template"}';
</script>
<script src="/static/js/swiftype_app_search.umd.min.js"></script>
<script type="text/javascript" src="/static/js/slick.min.js"></script>
<script type="text/javascript" src="/guide/static/docs.js"></script>

<script type="text/javascript">
window.initial_state = {}</script>
  </body>
</html>
